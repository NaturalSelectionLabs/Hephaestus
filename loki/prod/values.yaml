loki:
  enabled: true
  nodeSelector:
    rss3.io/usage: internal
  tolerations:
    - key: "rss3.io/usage"
      operator: "Equal"
      value: "internal"
      effect: "NoSchedule"
  persistence:
    enabled: true
    accessModes:
    - ReadWriteOnce
    size: 200Gi
    storageClassName: "alicloud-disk-ssd"
  config:
    compactor:
      retention_enabled: true
      retention_delete_delay: 2h
      retention_delete_worker_count: 150
    chunk_store_config:
      max_look_back_period: 168h
    server:
      grpc_server_max_recv_msg_size: 104857600
    limits_config:
      retention_period: 168h
      per_stream_rate_limit: "15MB"
      per_stream_rate_limit_burst: "30MB"
      ingestion_rate_mb: 15
      ingestion_burst_size_mb: 30
      max_entries_limit_per_query: 10000
      max_global_streams_per_user: 10000
    table_manager:
      retention_deletes_enabled: true
      retention_period: 168h

promtail:
  enabled: false

fluent-bit:
  enabled: false

grafana:
  enabled: false

prometheus:
  enabled: false

filebeat:
  enabled: true
  tolerations:
    - operator: "Exists"
  filebeatConfig:
    filebeat.yml: |
      logging.level: warning
      filebeat.inputs:
      - type: container
        format: cri
        tail_files: true
        paths:
          - /var/log/containers/*.log
        processors:
        - add_kubernetes_metadata:
            when:
              not:
                regexp:
                  message: "^\\[DATABEAT\\].*"
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
        - add_tags:
            when:
              regexp:
                message: "^\\[DATABEAT\\].*"
            tags: [databeat]
      output.logstash:
        hosts: ["logstash-loki.guardian:5044"]
  resources:
    requests:
      cpu: 100m
      memory: 300Mi
    limits:
      cpu: 2000m
      memory: 1024Mi

logstash:
  enabled: true
  fullnameOverride: logstash-loki
  nodeSelector:
    rss3.io/usage: internal
  tolerations:
    - key: "rss3.io/usage"
      operator: "Equal"
      value: "internal"
      effect: "NoSchedule"
  image: grafana/logstash-output-loki
  imageTag: "2.6.1-amd64"
  logstashConfig:
    logstash.yml: |
      http.host: "0.0.0.0"
  logstashPipeline:
    logstash.conf: |
      input {
        beats {
          port => 5044
        }
      }
      filter {
        if [kubernetes] {
          mutate {
            add_field => {
              "container_name" => "%{[kubernetes][container][name]}"
              "namespace" => "%{[kubernetes][namespace]}"
              "pod" => "%{[kubernetes][pod][name]}"
            }
            replace => { "host" => "%{[kubernetes][node][name]}"}
          }
        }

        if "databeat" in [tags] {
          dissect {
            mapping => {
              "message" => "[DATABEAT]%{msg}"
            }
          }
          json {
            source => "msg"
          }
          mutate {
            remove_field => ["msg", "message"]
          }
        }
      }
      output {
        if ("databeat" in [tags]) {
          elasticsearch {
            hosts => "elasticsearch-es-internal-http.elastic-system:9200"
            index => "%{[index]}-%{+YYYY.MM.dd}"
            user => "elastic"
            password => ""
          }
        } else {
          loki {
            url => "http://loki:3100/loki/api/v1/push"
          }
        }
        # stdout { codec => rubydebug }
      }
  resources:
    limits:
      cpu: 1200m
      memory: 2560Mi
